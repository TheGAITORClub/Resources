{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Images from Google Drive\n",
    "\n",
    "[Google Drive Link](https://drive.google.com/file/d/1Xi5qlD4vJkN5YDcvqMXST2jZXVSh7VWm/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Zip File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "# Make sure the zip file is uploaded to Colab, or in same directory as this file\n",
    "path_to_zip_file = \"./images.zip\"\n",
    "directory_to_extract_to = \"./\"\n",
    "with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
    "    zip_ref.extractall(directory_to_extract_to)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def show_image(img_path):\n",
    "    image = mpimg.imread(img_path)\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "current_dir = os.path.abspath(\".\")\n",
    "\n",
    "test_image_path = os.path.join(current_dir, 'images', 'train', 'dog', 'dog.1.jpg')\n",
    "show_image(test_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data from directories using Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "data_dir = os.path.join(current_dir, 'images', 'train')\n",
    "\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "batch_size = 15\n",
    "random_seed = 32601\n",
    "\n",
    "# where I got code from https://www.tensorflow.org/tutorials/load_data/images\n",
    "dataset = tf.keras.utils.image_dataset_from_directory(  # https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory\n",
    "    data_dir,\n",
    "    validation_split=0.25,\n",
    "    subset=\"training\",\n",
    "    seed=random_seed,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    interpolation='bilinear')\n",
    "\n",
    "dataset.class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imported again\n",
    "import matplotlib.pyplot as plt # https: // matplotlib.org/stable/gallery/index\n",
    "\n",
    "# what are the class names?\n",
    "class_names = dataset.class_names\n",
    "print(class_names)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in dataset.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# They are stretched...\n",
    "\n",
    "**Does that matter?**\n",
    "\n",
    "Idk, does it??\n",
    "\n",
    "**How can I change it?**\n",
    "\n",
    "What are some ideas?\n",
    "\n",
    "crop_to_aspect_ratio (change it and show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.keras.utils.image_dataset_from_directory(  # https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory\n",
    "    data_dir,\n",
    "    validation_split=0.25,\n",
    "    subset=\"training\",\n",
    "    seed=random_seed,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    interpolation='bilinear',\n",
    "    label_mode='categorical')\n",
    "\n",
    "valid = tf.keras.utils.image_dataset_from_directory(  # https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory\n",
    "    data_dir,\n",
    "    validation_split=0.25,\n",
    "    subset=\"validation\",\n",
    "    seed=random_seed,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    interpolation='bilinear',\n",
    "    label_mode='categorical',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "\n",
    "# datagen = ImageDataGenerator(  # https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "#     samplewise_center=True,\n",
    "#     rotation_range=15,\n",
    "#     zoom_range=0.1,\n",
    "#     width_shift_range=0.1,\n",
    "#     height_shift_range=0.1, \n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=False,\n",
    "# )\n",
    "\n",
    "# datagen.flow_from_dataframe(  # https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "#     data_dir, \n",
    "#     target_size=(img_height, img_width), \n",
    "#     batch_size=batch_size, \n",
    "#     class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Input Layer: It represent input image data. It will reshape image into single diminsion array. Example your image is 64x64 = 4096, it will convert to (4096,1) array.\n",
    " - Conv Layer: This layer will extract features from image.\n",
    " - Pooling Layer: This layerreduce the spatial volume of input image after convolution.\n",
    " - Fully Connected Layer: It connect the network from a layer to another layer\n",
    " - Output Layer: It is the predicted values layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras # https://www.tensorflow.org/api_docs/python/tf/keras/\n",
    "from tensorflow.keras.models import Sequential # https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n",
    "from tensorflow.keras.layers import ( # https://www.tensorflow.org/api_docs/python/tf/keras/layers\n",
    "    Dense,              # https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense\n",
    "    Conv2D,             # https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\n",
    "    MaxPool2D,          # https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D\n",
    "    Flatten,            # https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten\n",
    "    Dropout,            # https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout\n",
    "    BatchNormalization, # https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization\n",
    ")\n",
    "\n",
    "# Sequential model from https://www.kaggle.com/uysimty/keras-cnn-dog-or-cat-classification/notebook\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "# 2 because we have cat and dog classes\n",
    "model.add(Dense(2, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model.compile(loss=tf.losses.CategoricalCrossentropy(), optimizer='rmsprop', metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau # https://keras.io/callbacks/\n",
    "\n",
    "earlystop = EarlyStopping(patience=10)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
    "                                            patience=2,\n",
    "                                            verbose=1,\n",
    "                                            factor=0.5,\n",
    "                                            min_lr=0.00001)\n",
    "callbacks = [earlystop, learning_rate_reduction]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_validate = 18750\n",
    "total_train = 6250\n",
    "\n",
    "print (\"Total validation images: \", total_validate)\n",
    "print (\"Total train images: \", total_train)\n",
    "\n",
    "print(\"Validation Steps: \", total_validate//batch_size)\n",
    "print(\"Train Steps: \", total_train//batch_size)\n",
    "\n",
    "history = model.fit(train, validation_data=valid, epochs=50, callbacks=callbacks,\n",
    "                    validation_steps=total_validate//batch_size, steps_per_epoch=total_train//batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How did we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
    "ax1.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "ax1.set_xticks(np.arange(1, 128, 1))\n",
    "ax1.set_yticks(np.arange(0, 1, 0.1))\n",
    "\n",
    "ax2.plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
    "ax2.plot(history.history['val_acc'], color='r', label=\"Validation accuracy\")\n",
    "ax2.set_xticks(np.arange(1, 128, 1))\n",
    "\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
